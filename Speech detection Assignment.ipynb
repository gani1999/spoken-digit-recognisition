{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwoTWIysaNmc"
   },
   "source": [
    "# <font color='red'> Spoken Digit Recognition</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPO3mjDDaNmf"
   },
   "source": [
    "\n",
    "In this notebook, You will do Spoken Digit Recognition. \n",
    "\n",
    "Input - speech signal, output - digit number\n",
    "\n",
    "\n",
    "\n",
    "It contains  \n",
    "\n",
    "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
    "2. Training the LSTM with RAW data\n",
    "3. Converting to spectrogram and Training the LSTM network\n",
    "4. Creating the augmented data and doing step 2 and 3 again.  \n",
    "\n",
    "<font size=5>Instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. Please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_qGuPcj-aNmh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "##if you need any imports you can do that here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdhFzGK1aNmo"
   },
   "source": [
    "We shared recordings.zip, please unzip those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HDBcl_PUaNmp"
   },
   "outputs": [],
   "source": [
    "#read the all file names in the recordings folder given by us\n",
    "#(if you get entire path, it is very useful in future)\n",
    "#save those files names as list in \"all_files\"\n",
    "import os\n",
    "\n",
    "files= os.listdir('recordings')\n",
    "all_files=[]\n",
    "for file in files:\n",
    "    all_files.append(os.path.abspath(os.path.join('recordings',file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\Downloads\\\\spoken_digit\\\\spoken_digit\\\\recordings\\\\0_jackson_0.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NYYpfqoaNmv"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2oJSOmYBaNmx",
    "outputId": "d4509e7d-1cb6-4e7f-e469-ef40314a8510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_files():\n",
    "    temp = len(all_files)==2000\n",
    "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
    "    temp = temp and temp1\n",
    "    return temp\n",
    "grader_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZbhCvvRPPMw"
   },
   "source": [
    "## Exploring the sound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilJsqdhhPMed"
   },
   "outputs": [],
   "source": [
    "#It is a good programming practise to explore the dataset that you are dealing with. This dataset is unique in itself because it has sounds as input\n",
    "#https://colab.research.google.com/github/Tyler-Hilbert/AudioProcessingInPythonWorkshop/blob/master/AudioProcessingInPython.ipynb\n",
    "#visualize the data and write code to play 2-3 sound samples in the notebook for better understanding.\n",
    "#please go through the following reference video https://www.youtube.com/watch?v=37zCgCdV468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement thinkdsp (from versions: none)\n",
      "ERROR: No matching distribution found for thinkdsp\n"
     ]
    }
   ],
   "source": [
    "!pip install thinkdsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in audio file\n",
    "# FIXME - will this work for non wav files\n",
    "wave = thinkdsp.read_wave('AudioProcessingInPythonWorkshop/test.wav')\n",
    "\n",
    "# Grab first 10 seconds of audio (you can ignore me)\n",
    "clipLength = 10 # in seconds\n",
    "index = 0\n",
    "while (index < wave.ts.size and wave.ts[index] < clipLength):\n",
    "\tindex += 1\n",
    "# Remove extras\n",
    "wave.ts = wave.ts[:index]\n",
    "wave.ys = wave.ys[:index]\n",
    "\n",
    "# Plot spectrum of audio file\n",
    "spectrum = wave.make_spectrum()\n",
    "spectrum.plot()\n",
    "pyplot.show()\n",
    "\n",
    "# Play audio file\n",
    "wave.play()\n",
    "IPython.display.Audio('sound.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA0nAtjbQLmu"
   },
   "source": [
    "## Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bX_umjikPy5Y"
   },
   "outputs": [],
   "source": [
    "label=[]\n",
    "for path in files:\n",
    "    label.append(path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7Wx5tOjSPX2Y"
   },
   "outputs": [],
   "source": [
    "df_audio= pd.DataFrame(columns=['path','label'])\n",
    "df_audio['path']= all_files\n",
    "df_audio['label']= label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path label\n",
       "0  C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...     0\n",
       "1  C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...     0\n",
       "2  C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...     0\n",
       "3  C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...     0\n",
       "4  C:\\Users\\HP\\Downloads\\spoken_digit\\spoken_digi...     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKpYJ_LaNnD"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7Q8r_T8-aNnE",
    "outputId": "849e3f3e-e77c-492c-ba29-77508e74fc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_df():\n",
    "    flag_shape = df_audio.shape==(2000,2)\n",
    "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
    "    list_values = list(df_audio.label.value_counts())\n",
    "    flag_label = len(list_values)==10\n",
    "    flag_label2 = all([i==200 for i in list_values])\n",
    "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
    "    return final_flag\n",
    "grader_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [],
   "source": [
    "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
    "#use stratify sampling\n",
    "#use random state of 45\n",
    "#use test size of 30%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_audio['path'],df_audio['label'], test_size=0.3,stratify=df_audio['label'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPK3sbzUaNnW"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "chZzntKUaNnX",
    "outputId": "e2949c8b-2f00-434f-8403-56b577faf04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_split():\n",
    "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
    "    values_ytrain = list(y_train.value_counts())\n",
    "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
    "    values_ytest = list(y_test.value_counts())\n",
    "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
    "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
    "    return final_flag\n",
    "grader_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(y=samples, sr=sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rx97f8GGaNnh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1.8207456e-05, -8.338033e-05, -0.00010331021...</td>\n",
       "      <td>0.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9.6588104e-05, 0.00012566414, 0.00016156163, ...</td>\n",
       "      <td>0.314785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.00027579028, -0.00031114486, -0.000292675,...</td>\n",
       "      <td>0.349660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.00021909502, 0.0002477661, 0.00026524728, 0...</td>\n",
       "      <td>0.566893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-4.8777634e-05, -8.546371e-05, -0.0001339433,...</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [-1.8207456e-05, -8.338033e-05, -0.00010331021...  0.363900\n",
       "1  [9.6588104e-05, 0.00012566414, 0.00016156163, ...  0.314785\n",
       "2  [-0.00027579028, -0.00031114486, -0.000292675,...  0.349660\n",
       "3  [0.00021909502, 0.0002477661, 0.00026524728, 0...  0.566893\n",
       "4  [-4.8777634e-05, -8.546371e-05, -0.0001339433,...  0.509025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use load_wav function that was written above to get every wave. \n",
    "#save it in X_train_processed and X_test_processed\n",
    "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
    "X_train_processed = []\n",
    "for x in X_train:\n",
    "    X_train_processed.append(load_wav(x, get_duration=True))\n",
    "X_train_processed=pd.DataFrame(X_train_processed,columns=['raw_data','duration'])\n",
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7.5200514e-05, 0.00067946606, 0.0011661825, 0...</td>\n",
       "      <td>0.316281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00746698, -0.0061093145, -0.0028450494, 0....</td>\n",
       "      <td>0.374785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.010753613, -0.0025474587, 0.006818897, 0.0...</td>\n",
       "      <td>0.569751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.008190532, -0.005059408, 0.005092152, 0.01...</td>\n",
       "      <td>0.381270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.00034301207, 0.0002433633, 4.777004e-05, -0...</td>\n",
       "      <td>0.453878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [7.5200514e-05, 0.00067946606, 0.0011661825, 0...  0.316281\n",
       "1  [-0.00746698, -0.0061093145, -0.0028450494, 0....  0.374785\n",
       "2  [-0.010753613, -0.0025474587, 0.006818897, 0.0...  0.569751\n",
       "3  [-0.008190532, -0.005059408, 0.005092152, 0.01...  0.381270\n",
       "4  [0.00034301207, 0.0002433633, 4.777004e-05, -0...  0.453878"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed = []\n",
    "for x in X_test:\n",
    "    X_test_processed.append(load_wav(x, get_duration=True))\n",
    "X_test_processed=pd.DataFrame(X_test_processed,columns=['raw_data','duration'])\n",
    "X_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(X_train_processed['duration'])\n",
    "plt.title('train data duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(X_test_processed['duration'])\n",
    "plt.title('test data duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vvLhm1AqaNny",
    "outputId": "a4430992-0f16-4d24-de92-0a6fcec1df06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 0.1435374149659864\n",
      "10 percentile value is 0.25976870748299324\n",
      "20 percentile value is 0.29777777777777775\n",
      "30 percentile value is 0.3302766439909297\n",
      "40 percentile value is 0.3580498866213152\n",
      "50 percentile value is 0.38945578231292516\n",
      "60 percentile value is 0.4164172335600907\n",
      "70 percentile value is 0.44616780045351473\n",
      "80 percentile value is 0.48358276643990933\n",
      "90 percentile value is 0.5621632653061226\n",
      "100 percentile value is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for p in range(0,101,10):\n",
    "    print(p, \"percentile value is\", np.percentile(X_train_processed['duration'], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rSlVQh4CaNn2",
    "outputId": "d6970436-db83-4d01-c910-7ebe92baab41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 0.5621632653061226\n",
      "91 percentile value is 0.5790390022675738\n",
      "92 percentile value is 0.5933351473922903\n",
      "93 percentile value is 0.6066258503401363\n",
      "94 percentile value is 0.6213378684807256\n",
      "95 percentile value is 0.6346916099773242\n",
      "96 percentile value is 0.6484607709750566\n",
      "97 percentile value is 0.6743265306122448\n",
      "98 percentile value is 0.7120553287981859\n",
      "99 percentile value is 0.8067614512471656\n",
      "100 percentile value is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "for p in range(90,101):\n",
    "    print(p, \"percentile value is\", np.percentile(X_train_processed['duration'], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbMb4Y0RaNoA"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UMoyLLSAaNoF",
    "outputId": "cfb3ad33-3dc0-49e7-d078-8619b164b5db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_processed():\n",
    "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
    "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
    "    return flag_columns and flag_shape\n",
    "grader_processed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<b>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset.</b>\n",
    "\n",
    "<b>While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "</b>\n",
    "<b>Pad with Zero if length of sequence is less than 17640 else Truncate the number. </b>\n",
    "\n",
    "<b> Also create a masking vector for train and test. </b>\n",
    "\n",
    "<b> masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1-_r20BaNoW"
   },
   "outputs": [],
   "source": [
    "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "## save in the X_train_pad_seq, X_test_pad_seq\n",
    "## also Create masking vector X_train_mask, X_test_mask\n",
    "\n",
    "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad_seq=[]\n",
    "X_train_mask=[]\n",
    "for x in X_train_processed['raw_data']:\n",
    "    if len(x)<17640:\n",
    "        x1=np.concatenate((x , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_train_pad_seq.append(x1)\n",
    "        mask=np.concatenate((np.ones(len(x), dtype=bool) , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_train_mask.append(mask)\n",
    "        \n",
    "    else:\n",
    "        X_train_pad_seq.append(x[:17640])\n",
    "        X_train_mask.append(np.ones(17640, dtype=bool))\n",
    "        \n",
    "X_train_pad_seq= np.array(X_train_pad_seq)\n",
    "X_train_mask = np.array(X_train_mask)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad_seq=[]\n",
    "X_test_mask=[]\n",
    "for x in X_test_processed['raw_data']:\n",
    "    if len(x)<17640:\n",
    "        x1=np.concatenate((x , np.zeros(17640-len(x),dtype=bool)))\n",
    "        X_test_pad_seq.append(x1)\n",
    "        mask=np.concatenate((np.ones(len(x),dtype=bool) , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_test_mask.append(mask)\n",
    "        \n",
    "    else:\n",
    "        X_test_pad_seq.append(x[:17640])\n",
    "        X_test_mask.append(np.ones(17640,dtype=bool))\n",
    "        \n",
    "X_test_pad_seq= np.array(X_test_pad_seq)\n",
    "X_test_mask = np.array(X_test_mask)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEHMgm4DaNoe"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Th3KhplGaNof",
    "outputId": "5e783ec9-81d2-4156-9e88-efdee0ff8b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_padoutput():\n",
    "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
    "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
    "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
    "    return flag_padshape and flag_maskshape and flag_dtype\n",
    "grader_padoutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kaYQ1jaNop"
   },
   "source": [
    "### 1. Giving Raw data directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHxh3jTaNoq"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
    "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
    "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). Also check the datatype of class labels(y_values) and make sure that you convert your class labels  to integer datatype before fitting in the model.\n",
    "3. While defining your model make sure that you pass both the input layer and mask input layer as input to lstm layer as follows\n",
    "<img src='https://i.imgur.com/FvcgvbY.jpg'>\n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "\n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "X8yg951AaNor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8y1sgeVaNoy"
   },
   "outputs": [],
   "source": [
    "## as discussed above, please write the architecture of the model.\n",
    "## you will have two input layers in your model (data input layer and mask input layer)\n",
    "## make sure that you have defined the data type of masking layer as bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RPj_DGW2aNo9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "class Metrics(tf.keras.callbacks.Callback ):\n",
    "    def __init__(self,validation_data):\n",
    "\n",
    "        super().__init__()\n",
    "        self.x_test=validation_data[0]\n",
    "        self.y_test=validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        val_predict = (np.asarray(self.model.predict([self.x_test[0],self.x_test[1]])))\n",
    "        val_label=np.argmax(val_predict,axis=1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "        print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 17640)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 32)           4352        ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           2112        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           650         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,114\n",
      "Trainable params: 7,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer= Input(shape=(17640,1))\n",
    "input_layer2 = Input( shape=(17640,))\n",
    "lstm = LSTM(32, activation='relu')(inputs=input_layer, mask=input_layer2)\n",
    "dense= Dense(64, activation='relu')(lstm)\n",
    "output= Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model= Model([input_layer,input_layer2],output)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.apply(lambda x: int(x))\n",
    "y_test_int = y_test.apply(lambda x: int(x))\n",
    "y_train_int=y_train_int.values\n",
    "y_test_int=y_test_int.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "log_dir = os.path.join(\"logs1\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "\n",
    "filepath=\"model_save/weights-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_f1',  verbose=1, mode='auto')  \n",
    "metric = Metrics(validation_data=[[X_test_pad_seq,X_test_mask],y_test_int])\n",
    "\n",
    "callbacks= [tensorboard_callback,checkpoint, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3032 \n",
      "Epoch 1: saving model to model_save\\weights-01.hdf5\n",
      "Val_F1score =  0.10000000000000002\n",
      "117/117 [==============================] - 5137s 44s/step - loss: 2.3032 - val_loss: 2.3026\n",
      "Epoch 2/3\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3030 \n",
      "Epoch 2: saving model to model_save\\weights-02.hdf5\n",
      "Val_F1score =  0.10166666666666667\n",
      "117/117 [==============================] - 6415s 55s/step - loss: 2.3030 - val_loss: 2.3026\n",
      "Epoch 3/3\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3029 \n",
      "Epoch 3: saving model to model_save\\weights-03.hdf5\n",
      "Val_F1score =  0.10166666666666667\n",
      "117/117 [==============================] - 5230s 45s/step - loss: 2.3029 - val_loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185620f5e70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_pad_seq,X_train_mask], y_train_int, epochs=3,verbose=1,batch_size=12, callbacks =callbacks, validation_data=([X_test_pad_seq,X_test_mask],y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_F1score =  0.10166666666666667\n"
     ]
    }
   ],
   "source": [
    "val_predict = (np.asarray(model.predict([X_test_pad_seq,X_test_mask])))\n",
    "val_label=np.argmax(val_predict,axis=1)\n",
    "val_targ = y_test_int\n",
    "val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-676fa812152737ec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-676fa812152737ec\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs1/fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='model1.png'\n",
    "tf.keras.utils.plot_model(model,to_file=filepath,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "MzpPjxvHaNpJ"
   },
   "outputs": [],
   "source": [
    "#train your model\n",
    "#model1.fit([X_train_pad_seq,X_train_mask],y_train_int,.........)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
    "\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "B__rN4RjaNpc"
   },
   "outputs": [],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "X_train_spectrogram = convert_to_spectrogram(X_train_pad_seq)\n",
    "X_test_spectrogram = convert_to_spectrogram(X_test_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 64, 35)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1ynYZnaNpj"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oniXBXcsaNpk",
    "outputId": "0f94ec35-98af-4b98-c501-35cbbfbd0a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_spectrogram():\n",
    "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
    "    return flag_shape\n",
    "grader_spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "(ex: Output from LSTM will be  (None, time_steps, features) average the output of every time step i.e, you should get (None,time_steps) \n",
    "and then pass to dense layer )\n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaQjaiiGaNpv"
   },
   "outputs": [],
   "source": [
    "# write the architecture of the model\n",
    "#print model.summary and make sure that it is following point 2 mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "class Metrics(tf.keras.callbacks.Callback ):\n",
    "    def __init__(self,validation_data):\n",
    "\n",
    "        super().__init__()\n",
    "        self.x_test=validation_data[0]\n",
    "        self.y_test=validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label=np.argmax(val_predict,axis=1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "        print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.core import TFOpLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 35)]          0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64, 32)            8704      \n",
      "                                                                 \n",
      " tf.math.reduce_mean_7 (TFOp  (None, 64)               0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,114\n",
      "Trainable params: 11,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def mean_layer(x):\n",
    "    return tf.math.reduce_mean(x,axis=2)\n",
    "\n",
    "input_layer= Input(shape=(64,35))\n",
    "lstm = LSTM(32, activation='relu', return_sequences=True)(input_layer)\n",
    "mean= TFOpLambda(mean_layer)(lstm)\n",
    "#AvgPool = GlobalAveragePooling1D()(mean)\n",
    "dense= Dense(32, activation='relu')(mean)\n",
    "output= Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model1= Model(input_layer,output)\n",
    "model1.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics='accuracy')\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "log_dir = os.path.join(\"logs1\",'fits2', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "\n",
    "filepath=\"model_save/weights2-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_f1', verbose=1, mode='auto')  \n",
    "metric = Metrics(validation_data=[X_test_spectrogram,y_test_int])\n",
    "\n",
    "callbacks= [tensorboard_callback,checkpoint, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.4490 - accuracy: 0.1043\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.07333333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 2.4490 - accuracy: 0.1043 - val_loss: 2.5374 - val_accuracy: 0.0733\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.4156 - accuracy: 0.1164\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.08833333333333333\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 2.4156 - accuracy: 0.1164 - val_loss: 2.5509 - val_accuracy: 0.0883\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3964 - accuracy: 0.1093\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.125\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 2.3964 - accuracy: 0.1093 - val_loss: 2.5013 - val_accuracy: 0.1250\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3822 - accuracy: 0.1243\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.09\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.3822 - accuracy: 0.1243 - val_loss: 2.4600 - val_accuracy: 0.0900\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3596 - accuracy: 0.1386\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.10833333333333334\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 2.3596 - accuracy: 0.1386 - val_loss: 2.4462 - val_accuracy: 0.1083\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3412 - accuracy: 0.1257\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.115\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.3412 - accuracy: 0.1257 - val_loss: 2.4890 - val_accuracy: 0.1150\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3178 - accuracy: 0.1443\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.13833333333333334\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.3178 - accuracy: 0.1443 - val_loss: 2.4736 - val_accuracy: 0.1383\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3030 - accuracy: 0.1514\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.12166666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 2.3030 - accuracy: 0.1514 - val_loss: 2.4520 - val_accuracy: 0.1217\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2790 - accuracy: 0.1621\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.13833333333333334\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.2790 - accuracy: 0.1621 - val_loss: 2.4436 - val_accuracy: 0.1383\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2715 - accuracy: 0.1671\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.135\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 2.2715 - accuracy: 0.1671 - val_loss: 2.4271 - val_accuracy: 0.1350\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2619 - accuracy: 0.1593\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.13833333333333334\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 2.2619 - accuracy: 0.1593 - val_loss: 2.4695 - val_accuracy: 0.1383\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2541 - accuracy: 0.1664\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.18333333333333332\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 2.2541 - accuracy: 0.1664 - val_loss: 2.4065 - val_accuracy: 0.1833\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2489 - accuracy: 0.1757\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.17333333333333334\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2489 - accuracy: 0.1757 - val_loss: 2.3917 - val_accuracy: 0.1733\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2332 - accuracy: 0.1779\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.15666666666666668\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2332 - accuracy: 0.1779 - val_loss: 2.4398 - val_accuracy: 0.1567\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2308 - accuracy: 0.1814\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.14666666666666667\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2308 - accuracy: 0.1814 - val_loss: 2.3256 - val_accuracy: 0.1467\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2015 - accuracy: 0.1957\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.17166666666666666\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2015 - accuracy: 0.1957 - val_loss: 2.2785 - val_accuracy: 0.1717\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2217 - accuracy: 0.1936\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.16333333333333333\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 2.2217 - accuracy: 0.1936 - val_loss: 2.2559 - val_accuracy: 0.1633\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2161 - accuracy: 0.2064\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.21833333333333332\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2161 - accuracy: 0.2064 - val_loss: 2.4056 - val_accuracy: 0.2183\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1882 - accuracy: 0.2143\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.14166666666666666\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 2.1882 - accuracy: 0.2143 - val_loss: 2.3182 - val_accuracy: 0.1417\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1773 - accuracy: 0.2171\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.20666666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 2.1773 - accuracy: 0.2171 - val_loss: 2.2261 - val_accuracy: 0.2067\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1652 - accuracy: 0.2143\n",
      "Epoch 21: saving model to model_save\\weights2-21.hdf5\n",
      "Val_F1score =  0.19833333333333333\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 2.1652 - accuracy: 0.2143 - val_loss: 2.1925 - val_accuracy: 0.1983\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1595 - accuracy: 0.2157\n",
      "Epoch 22: saving model to model_save\\weights2-22.hdf5\n",
      "Val_F1score =  0.21666666666666667\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.1595 - accuracy: 0.2157 - val_loss: 2.1787 - val_accuracy: 0.2167\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1460 - accuracy: 0.2314\n",
      "Epoch 23: saving model to model_save\\weights2-23.hdf5\n",
      "Val_F1score =  0.22\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.1460 - accuracy: 0.2314 - val_loss: 2.1964 - val_accuracy: 0.2200\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1466 - accuracy: 0.2293\n",
      "Epoch 24: saving model to model_save\\weights2-24.hdf5\n",
      "Val_F1score =  0.19333333333333333\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.1466 - accuracy: 0.2293 - val_loss: 2.2250 - val_accuracy: 0.1933\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1176 - accuracy: 0.2479\n",
      "Epoch 25: saving model to model_save\\weights2-25.hdf5\n",
      "Val_F1score =  0.17166666666666666\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.1176 - accuracy: 0.2479 - val_loss: 2.1894 - val_accuracy: 0.1717\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1211 - accuracy: 0.2336\n",
      "Epoch 26: saving model to model_save\\weights2-26.hdf5\n",
      "Val_F1score =  0.27166666666666667\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 2.1211 - accuracy: 0.2336 - val_loss: 2.1122 - val_accuracy: 0.2717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1090 - accuracy: 0.2471\n",
      "Epoch 27: saving model to model_save\\weights2-27.hdf5\n",
      "Val_F1score =  0.21166666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 2.1090 - accuracy: 0.2471 - val_loss: 2.1911 - val_accuracy: 0.2117\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0909 - accuracy: 0.2386\n",
      "Epoch 28: saving model to model_save\\weights2-28.hdf5\n",
      "Val_F1score =  0.23333333333333334\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.0909 - accuracy: 0.2386 - val_loss: 2.1356 - val_accuracy: 0.2333\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0554 - accuracy: 0.2486\n",
      "Epoch 29: saving model to model_save\\weights2-29.hdf5\n",
      "Val_F1score =  0.245\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 2.0554 - accuracy: 0.2486 - val_loss: 2.1434 - val_accuracy: 0.2450\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0777 - accuracy: 0.2500\n",
      "Epoch 30: saving model to model_save\\weights2-30.hdf5\n",
      "Val_F1score =  0.24833333333333332\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 2.0777 - accuracy: 0.2500 - val_loss: 2.1327 - val_accuracy: 0.2483\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0440 - accuracy: 0.2593\n",
      "Epoch 31: saving model to model_save\\weights2-31.hdf5\n",
      "Val_F1score =  0.24\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 2.0440 - accuracy: 0.2593 - val_loss: 2.0547 - val_accuracy: 0.2400\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0480 - accuracy: 0.2621\n",
      "Epoch 32: saving model to model_save\\weights2-32.hdf5\n",
      "Val_F1score =  0.2683333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.0480 - accuracy: 0.2621 - val_loss: 2.1014 - val_accuracy: 0.2683\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0293 - accuracy: 0.2514\n",
      "Epoch 33: saving model to model_save\\weights2-33.hdf5\n",
      "Val_F1score =  0.22\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 2.0293 - accuracy: 0.2514 - val_loss: 2.0996 - val_accuracy: 0.2200\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0241 - accuracy: 0.2600\n",
      "Epoch 34: saving model to model_save\\weights2-34.hdf5\n",
      "Val_F1score =  0.27166666666666667\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 2.0241 - accuracy: 0.2600 - val_loss: 2.0566 - val_accuracy: 0.2717\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0015 - accuracy: 0.2814\n",
      "Epoch 35: saving model to model_save\\weights2-35.hdf5\n",
      "Val_F1score =  0.25666666666666665\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 2.0015 - accuracy: 0.2814 - val_loss: 2.0680 - val_accuracy: 0.2567\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9914 - accuracy: 0.2679\n",
      "Epoch 36: saving model to model_save\\weights2-36.hdf5\n",
      "Val_F1score =  0.265\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.9914 - accuracy: 0.2679 - val_loss: 2.0282 - val_accuracy: 0.2650\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9800 - accuracy: 0.2721\n",
      "Epoch 37: saving model to model_save\\weights2-37.hdf5\n",
      "Val_F1score =  0.24333333333333335\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.9800 - accuracy: 0.2721 - val_loss: 1.9895 - val_accuracy: 0.2433\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9767 - accuracy: 0.2757\n",
      "Epoch 38: saving model to model_save\\weights2-38.hdf5\n",
      "Val_F1score =  0.24833333333333332\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.9767 - accuracy: 0.2757 - val_loss: 2.0622 - val_accuracy: 0.2483\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2011 - accuracy: 0.2614\n",
      "Epoch 39: saving model to model_save\\weights2-39.hdf5\n",
      "Val_F1score =  0.24333333333333335\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 2.2011 - accuracy: 0.2614 - val_loss: 2.1328 - val_accuracy: 0.2433\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9312 - accuracy: 0.2857\n",
      "Epoch 40: saving model to model_save\\weights2-40.hdf5\n",
      "Val_F1score =  0.315\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.9312 - accuracy: 0.2857 - val_loss: 1.9098 - val_accuracy: 0.3150\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8680 - accuracy: 0.3121\n",
      "Epoch 41: saving model to model_save\\weights2-41.hdf5\n",
      "Val_F1score =  0.23833333333333334\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.8680 - accuracy: 0.3121 - val_loss: 1.9570 - val_accuracy: 0.2383\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8821 - accuracy: 0.2971\n",
      "Epoch 42: saving model to model_save\\weights2-42.hdf5\n",
      "Val_F1score =  0.3416666666666667\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 1.8821 - accuracy: 0.2971 - val_loss: 1.8551 - val_accuracy: 0.3417\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8358 - accuracy: 0.3243\n",
      "Epoch 43: saving model to model_save\\weights2-43.hdf5\n",
      "Val_F1score =  0.34833333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.8358 - accuracy: 0.3243 - val_loss: 1.8414 - val_accuracy: 0.3483\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8123 - accuracy: 0.3350\n",
      "Epoch 44: saving model to model_save\\weights2-44.hdf5\n",
      "Val_F1score =  0.31\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 1.8123 - accuracy: 0.3350 - val_loss: 1.8503 - val_accuracy: 0.3100\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7959 - accuracy: 0.3564\n",
      "Epoch 45: saving model to model_save\\weights2-45.hdf5\n",
      "Val_F1score =  0.3433333333333333\n",
      "117/117 [==============================] - 15s 124ms/step - loss: 1.7959 - accuracy: 0.3564 - val_loss: 1.8203 - val_accuracy: 0.3433\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7794 - accuracy: 0.3386\n",
      "Epoch 46: saving model to model_save\\weights2-46.hdf5\n",
      "Val_F1score =  0.295\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.7794 - accuracy: 0.3386 - val_loss: 1.7891 - val_accuracy: 0.2950\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7515 - accuracy: 0.3307\n",
      "Epoch 47: saving model to model_save\\weights2-47.hdf5\n",
      "Val_F1score =  0.3433333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.7515 - accuracy: 0.3307 - val_loss: 1.8176 - val_accuracy: 0.3433\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7482 - accuracy: 0.3514\n",
      "Epoch 48: saving model to model_save\\weights2-48.hdf5\n",
      "Val_F1score =  0.23833333333333334\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.7482 - accuracy: 0.3514 - val_loss: 1.8610 - val_accuracy: 0.2383\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7346 - accuracy: 0.3607\n",
      "Epoch 49: saving model to model_save\\weights2-49.hdf5\n",
      "Val_F1score =  0.3466666666666667\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.7346 - accuracy: 0.3607 - val_loss: 1.7741 - val_accuracy: 0.3467\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7052 - accuracy: 0.3607\n",
      "Epoch 50: saving model to model_save\\weights2-50.hdf5\n",
      "Val_F1score =  0.36\n",
      "117/117 [==============================] - 15s 124ms/step - loss: 1.7052 - accuracy: 0.3607 - val_loss: 1.8084 - val_accuracy: 0.3600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276266a2710>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=50,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7144 - accuracy: 0.3571\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.37666666666666665\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 1.7144 - accuracy: 0.3571 - val_loss: 1.7144 - val_accuracy: 0.3767\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6762 - accuracy: 0.3779\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.375\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.6762 - accuracy: 0.3779 - val_loss: 1.7140 - val_accuracy: 0.3750\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6561 - accuracy: 0.3814\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.325\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.6561 - accuracy: 0.3814 - val_loss: 1.6915 - val_accuracy: 0.3250\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6774 - accuracy: 0.3600\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.36499999999999994\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.6774 - accuracy: 0.3600 - val_loss: 1.7180 - val_accuracy: 0.3650\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6567 - accuracy: 0.3686\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.2866666666666667\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.6567 - accuracy: 0.3686 - val_loss: 1.7836 - val_accuracy: 0.2867\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6269 - accuracy: 0.3721\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.33\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.6269 - accuracy: 0.3721 - val_loss: 1.7445 - val_accuracy: 0.3300\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6273 - accuracy: 0.3800\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.36833333333333335\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.6273 - accuracy: 0.3800 - val_loss: 1.6869 - val_accuracy: 0.3683\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6054 - accuracy: 0.3736\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.37166666666666665\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.6054 - accuracy: 0.3736 - val_loss: 1.7028 - val_accuracy: 0.3717\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5759 - accuracy: 0.3843\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.405\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.5759 - accuracy: 0.3843 - val_loss: 1.6101 - val_accuracy: 0.4050\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5973 - accuracy: 0.3707\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.315\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.5973 - accuracy: 0.3707 - val_loss: 1.8351 - val_accuracy: 0.3150\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6269 - accuracy: 0.3550\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.4000000000000001\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.6269 - accuracy: 0.3550 - val_loss: 1.6068 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5338 - accuracy: 0.4086\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.43666666666666665\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.5338 - accuracy: 0.4086 - val_loss: 1.5771 - val_accuracy: 0.4367\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5267 - accuracy: 0.4186\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.38666666666666666\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.5267 - accuracy: 0.4186 - val_loss: 1.6163 - val_accuracy: 0.3867\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5385 - accuracy: 0.4093\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.31833333333333336\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.5385 - accuracy: 0.4093 - val_loss: 1.9398 - val_accuracy: 0.3183\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 0.4150\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.42333333333333334\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.5330 - accuracy: 0.4150 - val_loss: 1.5424 - val_accuracy: 0.4233\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4704 - accuracy: 0.4336\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.35500000000000004\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.4704 - accuracy: 0.4336 - val_loss: 1.6463 - val_accuracy: 0.3550\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4983 - accuracy: 0.4193\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.37333333333333335\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.4983 - accuracy: 0.4193 - val_loss: 1.5740 - val_accuracy: 0.3733\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4814 - accuracy: 0.4136\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.4483333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.4814 - accuracy: 0.4136 - val_loss: 1.5103 - val_accuracy: 0.4483\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.4314\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.37333333333333335\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 1.4639 - accuracy: 0.4314 - val_loss: 1.5668 - val_accuracy: 0.3733\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4675 - accuracy: 0.4400\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.43833333333333335\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.4675 - accuracy: 0.4400 - val_loss: 1.5116 - val_accuracy: 0.4383\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4485 - accuracy: 0.4393\n",
      "Epoch 21: saving model to model_save\\weights2-21.hdf5\n",
      "Val_F1score =  0.33166666666666667\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.4485 - accuracy: 0.4393 - val_loss: 1.6472 - val_accuracy: 0.3317\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4569 - accuracy: 0.4386\n",
      "Epoch 22: saving model to model_save\\weights2-22.hdf5\n",
      "Val_F1score =  0.46\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.4569 - accuracy: 0.4386 - val_loss: 1.4605 - val_accuracy: 0.4600\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4206 - accuracy: 0.4614\n",
      "Epoch 23: saving model to model_save\\weights2-23.hdf5\n",
      "Val_F1score =  0.40333333333333327\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.4206 - accuracy: 0.4614 - val_loss: 1.5352 - val_accuracy: 0.4033\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3947 - accuracy: 0.4571\n",
      "Epoch 24: saving model to model_save\\weights2-24.hdf5\n",
      "Val_F1score =  0.41833333333333333\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.3947 - accuracy: 0.4571 - val_loss: 1.4895 - val_accuracy: 0.4183\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4115 - accuracy: 0.4321\n",
      "Epoch 25: saving model to model_save\\weights2-25.hdf5\n",
      "Val_F1score =  0.43666666666666665\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.4115 - accuracy: 0.4321 - val_loss: 1.4716 - val_accuracy: 0.4367\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3589 - accuracy: 0.4800\n",
      "Epoch 26: saving model to model_save\\weights2-26.hdf5\n",
      "Val_F1score =  0.41833333333333333\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 1.3589 - accuracy: 0.4800 - val_loss: 1.4585 - val_accuracy: 0.4183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3739 - accuracy: 0.4700\n",
      "Epoch 27: saving model to model_save\\weights2-27.hdf5\n",
      "Val_F1score =  0.415\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.3739 - accuracy: 0.4700 - val_loss: 1.4756 - val_accuracy: 0.4150\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3396 - accuracy: 0.4843\n",
      "Epoch 28: saving model to model_save\\weights2-28.hdf5\n",
      "Val_F1score =  0.5033333333333333\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.3396 - accuracy: 0.4843 - val_loss: 1.3713 - val_accuracy: 0.5033\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3655 - accuracy: 0.4693\n",
      "Epoch 29: saving model to model_save\\weights2-29.hdf5\n",
      "Val_F1score =  0.4483333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.3655 - accuracy: 0.4693 - val_loss: 1.4405 - val_accuracy: 0.4483\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.4714\n",
      "Epoch 30: saving model to model_save\\weights2-30.hdf5\n",
      "Val_F1score =  0.435\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.3324 - accuracy: 0.4714 - val_loss: 1.4815 - val_accuracy: 0.4350\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3357 - accuracy: 0.4786\n",
      "Epoch 31: saving model to model_save\\weights2-31.hdf5\n",
      "Val_F1score =  0.445\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 1.3357 - accuracy: 0.4786 - val_loss: 1.4311 - val_accuracy: 0.4450\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3230 - accuracy: 0.4686\n",
      "Epoch 32: saving model to model_save\\weights2-32.hdf5\n",
      "Val_F1score =  0.5033333333333333\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.3230 - accuracy: 0.4686 - val_loss: 1.3588 - val_accuracy: 0.5033\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3482 - accuracy: 0.4621\n",
      "Epoch 33: saving model to model_save\\weights2-33.hdf5\n",
      "Val_F1score =  0.4633333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.3482 - accuracy: 0.4621 - val_loss: 1.4262 - val_accuracy: 0.4633\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2695 - accuracy: 0.5086\n",
      "Epoch 34: saving model to model_save\\weights2-34.hdf5\n",
      "Val_F1score =  0.4583333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.2695 - accuracy: 0.5086 - val_loss: 1.4224 - val_accuracy: 0.4583\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2932 - accuracy: 0.4771\n",
      "Epoch 35: saving model to model_save\\weights2-35.hdf5\n",
      "Val_F1score =  0.5233333333333333\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.2932 - accuracy: 0.4771 - val_loss: 1.3308 - val_accuracy: 0.5233\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2840 - accuracy: 0.4993\n",
      "Epoch 36: saving model to model_save\\weights2-36.hdf5\n",
      "Val_F1score =  0.435\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.2840 - accuracy: 0.4993 - val_loss: 1.4303 - val_accuracy: 0.4350\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2746 - accuracy: 0.5200\n",
      "Epoch 37: saving model to model_save\\weights2-37.hdf5\n",
      "Val_F1score =  0.49166666666666664\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.2746 - accuracy: 0.5200 - val_loss: 1.3430 - val_accuracy: 0.4917\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2019 - accuracy: 0.5329\n",
      "Epoch 38: saving model to model_save\\weights2-38.hdf5\n",
      "Val_F1score =  0.48\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.2019 - accuracy: 0.5329 - val_loss: 1.3661 - val_accuracy: 0.4800\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2165 - accuracy: 0.5357\n",
      "Epoch 39: saving model to model_save\\weights2-39.hdf5\n",
      "Val_F1score =  0.515\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 1.2165 - accuracy: 0.5357 - val_loss: 1.3153 - val_accuracy: 0.5150\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2148 - accuracy: 0.5200\n",
      "Epoch 40: saving model to model_save\\weights2-40.hdf5\n",
      "Val_F1score =  0.5216666666666666\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 1.2148 - accuracy: 0.5200 - val_loss: 1.2831 - val_accuracy: 0.5217\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1586 - accuracy: 0.5493\n",
      "Epoch 41: saving model to model_save\\weights2-41.hdf5\n",
      "Val_F1score =  0.5066666666666667\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 1.1586 - accuracy: 0.5493 - val_loss: 1.3236 - val_accuracy: 0.5067\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1580 - accuracy: 0.5621\n",
      "Epoch 42: saving model to model_save\\weights2-42.hdf5\n",
      "Val_F1score =  0.52\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 1.1580 - accuracy: 0.5621 - val_loss: 1.2289 - val_accuracy: 0.5200\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1527 - accuracy: 0.5450\n",
      "Epoch 43: saving model to model_save\\weights2-43.hdf5\n",
      "Val_F1score =  0.4716666666666666\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 1.1527 - accuracy: 0.5450 - val_loss: 1.3443 - val_accuracy: 0.4717\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1349 - accuracy: 0.5686\n",
      "Epoch 44: saving model to model_save\\weights2-44.hdf5\n",
      "Val_F1score =  0.5566666666666666\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 1.1349 - accuracy: 0.5686 - val_loss: 1.2212 - val_accuracy: 0.5567\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1447 - accuracy: 0.5650\n",
      "Epoch 45: saving model to model_save\\weights2-45.hdf5\n",
      "Val_F1score =  0.4533333333333333\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 1.1447 - accuracy: 0.5650 - val_loss: 1.5798 - val_accuracy: 0.4533\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1360 - accuracy: 0.5700\n",
      "Epoch 46: saving model to model_save\\weights2-46.hdf5\n",
      "Val_F1score =  0.57\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 1.1360 - accuracy: 0.5700 - val_loss: 1.1821 - val_accuracy: 0.5700\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0791 - accuracy: 0.5714\n",
      "Epoch 47: saving model to model_save\\weights2-47.hdf5\n",
      "Val_F1score =  0.5666666666666667\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 1.0791 - accuracy: 0.5714 - val_loss: 1.1814 - val_accuracy: 0.5667\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0963 - accuracy: 0.5786\n",
      "Epoch 48: saving model to model_save\\weights2-48.hdf5\n",
      "Val_F1score =  0.5716666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 1.0963 - accuracy: 0.5786 - val_loss: 1.1550 - val_accuracy: 0.5717\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.6079\n",
      "Epoch 49: saving model to model_save\\weights2-49.hdf5\n",
      "Val_F1score =  0.5716666666666667\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 1.0186 - accuracy: 0.6079 - val_loss: 1.1459 - val_accuracy: 0.5717\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.5986\n",
      "Epoch 50: saving model to model_save\\weights2-50.hdf5\n",
      "Val_F1score =  0.5816666666666667\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 1.0341 - accuracy: 0.5986 - val_loss: 1.1247 - val_accuracy: 0.5817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27626c4e4a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=50,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6093\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.585\n",
      "117/117 [==============================] - 15s 132ms/step - loss: 1.0006 - accuracy: 0.6093 - val_loss: 1.0448 - val_accuracy: 0.5850\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.6007\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.5733333333333334\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 1.0292 - accuracy: 0.6007 - val_loss: 1.1188 - val_accuracy: 0.5733\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9854 - accuracy: 0.6293\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.555\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.9854 - accuracy: 0.6293 - val_loss: 1.1204 - val_accuracy: 0.5550\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9774 - accuracy: 0.6379\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.5833333333333334\n",
      "117/117 [==============================] - 14s 124ms/step - loss: 0.9774 - accuracy: 0.6379 - val_loss: 1.0893 - val_accuracy: 0.5833\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.6486\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.6083333333333333\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.9177 - accuracy: 0.6486 - val_loss: 1.0156 - val_accuracy: 0.6083\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8978 - accuracy: 0.6521\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.6183333333333333\n",
      "117/117 [==============================] - 16s 135ms/step - loss: 0.8978 - accuracy: 0.6521 - val_loss: 0.9907 - val_accuracy: 0.6183\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9582 - accuracy: 0.6207\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.66\n",
      "117/117 [==============================] - 18s 152ms/step - loss: 0.9582 - accuracy: 0.6207 - val_loss: 0.9342 - val_accuracy: 0.6600\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9486 - accuracy: 0.6436\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.6333333333333333\n",
      "117/117 [==============================] - 17s 150ms/step - loss: 0.9486 - accuracy: 0.6436 - val_loss: 0.9680 - val_accuracy: 0.6333\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8967 - accuracy: 0.6571\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.61\n",
      "117/117 [==============================] - 18s 152ms/step - loss: 0.8967 - accuracy: 0.6571 - val_loss: 1.0376 - val_accuracy: 0.6100\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8535 - accuracy: 0.6757\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.6616666666666666\n",
      "117/117 [==============================] - 17s 148ms/step - loss: 0.8535 - accuracy: 0.6757 - val_loss: 0.8907 - val_accuracy: 0.6617\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8432 - accuracy: 0.6671\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.6433333333333333\n",
      "117/117 [==============================] - 17s 146ms/step - loss: 0.8432 - accuracy: 0.6671 - val_loss: 0.9883 - val_accuracy: 0.6433\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8352 - accuracy: 0.6793\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.6233333333333333\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 0.8352 - accuracy: 0.6793 - val_loss: 1.0541 - val_accuracy: 0.6233\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.7021\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.64\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 0.8187 - accuracy: 0.7021 - val_loss: 0.9599 - val_accuracy: 0.6400\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8113 - accuracy: 0.6829\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.6933333333333334\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 0.8113 - accuracy: 0.6829 - val_loss: 0.8771 - val_accuracy: 0.6933\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 364.5999 - accuracy: 0.4643\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.175\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 364.5999 - accuracy: 0.4643 - val_loss: 2.4818 - val_accuracy: 0.1750\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1939 - accuracy: 0.1850\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.18166666666666664\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 2.1939 - accuracy: 0.1850 - val_loss: 2.1650 - val_accuracy: 0.1817\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1589 - accuracy: 0.1957\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.17\n",
      "117/117 [==============================] - 18s 156ms/step - loss: 2.1589 - accuracy: 0.1957 - val_loss: 2.1318 - val_accuracy: 0.1700\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1288 - accuracy: 0.1879\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.15666666666666668\n",
      "117/117 [==============================] - 18s 157ms/step - loss: 2.1288 - accuracy: 0.1879 - val_loss: 2.1100 - val_accuracy: 0.1567\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1092 - accuracy: 0.1771\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.19\n",
      "117/117 [==============================] - 18s 150ms/step - loss: 2.1092 - accuracy: 0.1771 - val_loss: 2.0853 - val_accuracy: 0.1900\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0860 - accuracy: 0.1943\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.19333333333333333\n",
      "117/117 [==============================] - 17s 148ms/step - loss: 2.0860 - accuracy: 0.1943 - val_loss: 2.0654 - val_accuracy: 0.1933\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0669 - accuracy: 0.2093\n",
      "Epoch 21: saving model to model_save\\weights2-21.hdf5\n",
      "Val_F1score =  0.20000000000000004\n",
      "117/117 [==============================] - 18s 151ms/step - loss: 2.0669 - accuracy: 0.2093 - val_loss: 2.0508 - val_accuracy: 0.2000\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0486 - accuracy: 0.2114\n",
      "Epoch 22: saving model to model_save\\weights2-22.hdf5\n",
      "Val_F1score =  0.18666666666666668\n",
      "117/117 [==============================] - 18s 150ms/step - loss: 2.0486 - accuracy: 0.2114 - val_loss: 2.0352 - val_accuracy: 0.1867\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0327 - accuracy: 0.2143\n",
      "Epoch 23: saving model to model_save\\weights2-23.hdf5\n",
      "Val_F1score =  0.20333333333333334\n",
      "117/117 [==============================] - 17s 149ms/step - loss: 2.0327 - accuracy: 0.2143 - val_loss: 2.0150 - val_accuracy: 0.2033\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0185 - accuracy: 0.2314\n",
      "Epoch 24: saving model to model_save\\weights2-24.hdf5\n",
      "Val_F1score =  0.19333333333333333\n",
      "117/117 [==============================] - 17s 147ms/step - loss: 2.0185 - accuracy: 0.2314 - val_loss: 2.0009 - val_accuracy: 0.1933\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0000 - accuracy: 0.2321\n",
      "Epoch 25: saving model to model_save\\weights2-25.hdf5\n",
      "Val_F1score =  0.19666666666666666\n",
      "117/117 [==============================] - 17s 149ms/step - loss: 2.0000 - accuracy: 0.2321 - val_loss: 1.9961 - val_accuracy: 0.1967\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9835 - accuracy: 0.2564\n",
      "Epoch 26: saving model to model_save\\weights2-26.hdf5\n",
      "Val_F1score =  0.25166666666666665\n",
      "117/117 [==============================] - 18s 150ms/step - loss: 1.9835 - accuracy: 0.2564 - val_loss: 1.9625 - val_accuracy: 0.2517\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9657 - accuracy: 0.2879\n",
      "Epoch 27: saving model to model_save\\weights2-27.hdf5\n",
      "Val_F1score =  0.235\n",
      "117/117 [==============================] - 18s 154ms/step - loss: 1.9657 - accuracy: 0.2879 - val_loss: 1.9488 - val_accuracy: 0.2350\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9507 - accuracy: 0.2929\n",
      "Epoch 28: saving model to model_save\\weights2-28.hdf5\n",
      "Val_F1score =  0.2816666666666667\n",
      "117/117 [==============================] - 18s 153ms/step - loss: 1.9507 - accuracy: 0.2929 - val_loss: 1.9358 - val_accuracy: 0.2817\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9332 - accuracy: 0.2950\n",
      "Epoch 29: saving model to model_save\\weights2-29.hdf5\n",
      "Val_F1score =  0.30666666666666664\n",
      "117/117 [==============================] - 18s 151ms/step - loss: 1.9332 - accuracy: 0.2950 - val_loss: 1.9271 - val_accuracy: 0.3067\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9171 - accuracy: 0.2993\n",
      "Epoch 30: saving model to model_save\\weights2-30.hdf5\n",
      "Val_F1score =  0.29333333333333333\n",
      "117/117 [==============================] - 18s 152ms/step - loss: 1.9171 - accuracy: 0.2993 - val_loss: 2.0263 - val_accuracy: 0.2933\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8980 - accuracy: 0.3114\n",
      "Epoch 31: saving model to model_save\\weights2-31.hdf5\n",
      "Val_F1score =  0.29333333333333333\n",
      "117/117 [==============================] - 18s 150ms/step - loss: 1.8980 - accuracy: 0.3114 - val_loss: 1.9165 - val_accuracy: 0.2933\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8761 - accuracy: 0.3236\n",
      "Epoch 32: saving model to model_save\\weights2-32.hdf5\n",
      "Val_F1score =  0.2733333333333333\n",
      "117/117 [==============================] - 17s 148ms/step - loss: 1.8761 - accuracy: 0.3236 - val_loss: 1.9212 - val_accuracy: 0.2733\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8566 - accuracy: 0.3264\n",
      "Epoch 33: saving model to model_save\\weights2-33.hdf5\n",
      "Val_F1score =  0.305\n",
      "117/117 [==============================] - 18s 150ms/step - loss: 1.8566 - accuracy: 0.3264 - val_loss: 1.8906 - val_accuracy: 0.3050\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8311 - accuracy: 0.3271\n",
      "Epoch 34: saving model to model_save\\weights2-34.hdf5\n",
      "Val_F1score =  0.36\n",
      "117/117 [==============================] - 18s 151ms/step - loss: 1.8311 - accuracy: 0.3271 - val_loss: 1.8936 - val_accuracy: 0.3600\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7998 - accuracy: 0.3307\n",
      "Epoch 35: saving model to model_save\\weights2-35.hdf5\n",
      "Val_F1score =  0.32666666666666666\n",
      "117/117 [==============================] - 18s 151ms/step - loss: 1.7998 - accuracy: 0.3307 - val_loss: 1.8436 - val_accuracy: 0.3267\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7767 - accuracy: 0.3486\n",
      "Epoch 36: saving model to model_save\\weights2-36.hdf5\n",
      "Val_F1score =  0.31666666666666665\n",
      "117/117 [==============================] - 17s 148ms/step - loss: 1.7767 - accuracy: 0.3486 - val_loss: 1.8144 - val_accuracy: 0.3167\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7514 - accuracy: 0.3514\n",
      "Epoch 37: saving model to model_save\\weights2-37.hdf5\n",
      "Val_F1score =  0.33666666666666667\n",
      "117/117 [==============================] - 17s 147ms/step - loss: 1.7514 - accuracy: 0.3514 - val_loss: 1.8313 - val_accuracy: 0.3367\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7574 - accuracy: 0.3607\n",
      "Epoch 38: saving model to model_save\\weights2-38.hdf5\n",
      "Val_F1score =  0.3233333333333333\n",
      "117/117 [==============================] - 17s 149ms/step - loss: 1.7574 - accuracy: 0.3607 - val_loss: 1.7545 - val_accuracy: 0.3233\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.7368 - accuracy: 0.3600\n",
      "Epoch 39: saving model to model_save\\weights2-39.hdf5\n",
      "Val_F1score =  0.32\n",
      "117/117 [==============================] - 17s 149ms/step - loss: 1.7368 - accuracy: 0.3600 - val_loss: 1.7089 - val_accuracy: 0.3200\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6825 - accuracy: 0.3700\n",
      "Epoch 40: saving model to model_save\\weights2-40.hdf5\n",
      "Val_F1score =  0.345\n",
      "117/117 [==============================] - 14s 121ms/step - loss: 1.6825 - accuracy: 0.3700 - val_loss: 1.6678 - val_accuracy: 0.3450\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6536 - accuracy: 0.3821\n",
      "Epoch 41: saving model to model_save\\weights2-41.hdf5\n",
      "Val_F1score =  0.37166666666666665\n",
      "117/117 [==============================] - 13s 111ms/step - loss: 1.6536 - accuracy: 0.3821 - val_loss: 1.6482 - val_accuracy: 0.3717\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6351 - accuracy: 0.3936\n",
      "Epoch 42: saving model to model_save\\weights2-42.hdf5\n",
      "Val_F1score =  0.38166666666666665\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.6351 - accuracy: 0.3936 - val_loss: 1.6399 - val_accuracy: 0.3817\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6033 - accuracy: 0.4129\n",
      "Epoch 43: saving model to model_save\\weights2-43.hdf5\n",
      "Val_F1score =  0.3633333333333333\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 1.6033 - accuracy: 0.4129 - val_loss: 1.6326 - val_accuracy: 0.3633\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5657 - accuracy: 0.4207\n",
      "Epoch 44: saving model to model_save\\weights2-44.hdf5\n",
      "Val_F1score =  0.38333333333333336\n",
      "117/117 [==============================] - 13s 110ms/step - loss: 1.5657 - accuracy: 0.4207 - val_loss: 1.5626 - val_accuracy: 0.3833\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.4307\n",
      "Epoch 45: saving model to model_save\\weights2-45.hdf5\n",
      "Val_F1score =  0.43833333333333335\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.5289 - accuracy: 0.4307 - val_loss: 1.5996 - val_accuracy: 0.4383\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4938 - accuracy: 0.4536\n",
      "Epoch 46: saving model to model_save\\weights2-46.hdf5\n",
      "Val_F1score =  0.42666666666666675\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 1.4938 - accuracy: 0.4536 - val_loss: 1.4919 - val_accuracy: 0.4267\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 0.4429\n",
      "Epoch 47: saving model to model_save\\weights2-47.hdf5\n",
      "Val_F1score =  0.44666666666666666\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.4543 - accuracy: 0.4429 - val_loss: 1.4827 - val_accuracy: 0.4467\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4157 - accuracy: 0.4671\n",
      "Epoch 48: saving model to model_save\\weights2-48.hdf5\n",
      "Val_F1score =  0.4633333333333333\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 1.4157 - accuracy: 0.4671 - val_loss: 1.4261 - val_accuracy: 0.4633\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3814 - accuracy: 0.4500\n",
      "Epoch 49: saving model to model_save\\weights2-49.hdf5\n",
      "Val_F1score =  0.45666666666666667\n",
      "117/117 [==============================] - 13s 111ms/step - loss: 1.3814 - accuracy: 0.4500 - val_loss: 1.4059 - val_accuracy: 0.4567\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3451 - accuracy: 0.4507\n",
      "Epoch 50: saving model to model_save\\weights2-50.hdf5\n",
      "Val_F1score =  0.48333333333333334\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.3451 - accuracy: 0.4507 - val_loss: 1.3499 - val_accuracy: 0.4833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27626d39210>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=50,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.4871\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.445\n",
      "117/117 [==============================] - 12s 103ms/step - loss: 1.3085 - accuracy: 0.4871 - val_loss: 1.3783 - val_accuracy: 0.4450\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2628 - accuracy: 0.5200\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.515\n",
      "117/117 [==============================] - 13s 110ms/step - loss: 1.2628 - accuracy: 0.5200 - val_loss: 1.2908 - val_accuracy: 0.5150\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5250\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.5083333333333333\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 1.2418 - accuracy: 0.5250 - val_loss: 1.2808 - val_accuracy: 0.5083\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2934 - accuracy: 0.5129\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.46166666666666667\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.2934 - accuracy: 0.5129 - val_loss: 1.3641 - val_accuracy: 0.4617\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2767 - accuracy: 0.4936\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.4816666666666667\n",
      "117/117 [==============================] - 13s 110ms/step - loss: 1.2767 - accuracy: 0.4936 - val_loss: 1.3190 - val_accuracy: 0.4817\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2517 - accuracy: 0.4936\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.51\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 1.2517 - accuracy: 0.4936 - val_loss: 1.2547 - val_accuracy: 0.5100\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2187 - accuracy: 0.5179\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.5066666666666667\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 1.2187 - accuracy: 0.5179 - val_loss: 1.2310 - val_accuracy: 0.5067\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.5064\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.4683333333333333\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 1.2298 - accuracy: 0.5064 - val_loss: 1.2599 - val_accuracy: 0.4683\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1807 - accuracy: 0.5321\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.525\n",
      "117/117 [==============================] - 13s 111ms/step - loss: 1.1807 - accuracy: 0.5321 - val_loss: 1.2106 - val_accuracy: 0.5250\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1634 - accuracy: 0.5436\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.535\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 1.1634 - accuracy: 0.5436 - val_loss: 1.1642 - val_accuracy: 0.5350\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1393 - accuracy: 0.5600\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.5283333333333333\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 1.1393 - accuracy: 0.5600 - val_loss: 1.1590 - val_accuracy: 0.5283\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1077 - accuracy: 0.5679\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.5533333333333333\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 1.1077 - accuracy: 0.5679 - val_loss: 1.1227 - val_accuracy: 0.5533\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1023 - accuracy: 0.5693\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.5283333333333333\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.1023 - accuracy: 0.5693 - val_loss: 1.1275 - val_accuracy: 0.5283\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0850 - accuracy: 0.5664\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.5516666666666666\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 1.0850 - accuracy: 0.5664 - val_loss: 1.1214 - val_accuracy: 0.5517\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0609 - accuracy: 0.5764\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.5183333333333333\n",
      "117/117 [==============================] - 14s 115ms/step - loss: 1.0609 - accuracy: 0.5764 - val_loss: 1.2025 - val_accuracy: 0.5183\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0489 - accuracy: 0.5886\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.555\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 1.0489 - accuracy: 0.5886 - val_loss: 1.0871 - val_accuracy: 0.5550\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0345 - accuracy: 0.5914\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.5366666666666666\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.0345 - accuracy: 0.5914 - val_loss: 1.1346 - val_accuracy: 0.5367\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.5779\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.5783333333333334\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 1.0295 - accuracy: 0.5779 - val_loss: 1.0425 - val_accuracy: 0.5783\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9853 - accuracy: 0.5993\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.585\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 0.9853 - accuracy: 0.5993 - val_loss: 1.0356 - val_accuracy: 0.5850\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9119 - accuracy: 0.6479\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.6183333333333333\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.9119 - accuracy: 0.6479 - val_loss: 1.0032 - val_accuracy: 0.6183\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.6679\n",
      "Epoch 21: saving model to model_save\\weights2-21.hdf5\n",
      "Val_F1score =  0.6366666666666667\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.8701 - accuracy: 0.6679 - val_loss: 0.9387 - val_accuracy: 0.6367\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.6857\n",
      "Epoch 22: saving model to model_save\\weights2-22.hdf5\n",
      "Val_F1score =  0.6566666666666666\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.8263 - accuracy: 0.6857 - val_loss: 0.8928 - val_accuracy: 0.6567\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7862 - accuracy: 0.6857\n",
      "Epoch 23: saving model to model_save\\weights2-23.hdf5\n",
      "Val_F1score =  0.6583333333333333\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.7862 - accuracy: 0.6857 - val_loss: 0.9103 - val_accuracy: 0.6583\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.6836\n",
      "Epoch 24: saving model to model_save\\weights2-24.hdf5\n",
      "Val_F1score =  0.6316666666666667\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.7974 - accuracy: 0.6836 - val_loss: 0.9446 - val_accuracy: 0.6317\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.6993\n",
      "Epoch 25: saving model to model_save\\weights2-25.hdf5\n",
      "Val_F1score =  0.675\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.7710 - accuracy: 0.6993 - val_loss: 0.8733 - val_accuracy: 0.6750\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.6943\n",
      "Epoch 26: saving model to model_save\\weights2-26.hdf5\n",
      "Val_F1score =  0.64\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.7668 - accuracy: 0.6943 - val_loss: 0.8896 - val_accuracy: 0.6400\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.6936\n",
      "Epoch 27: saving model to model_save\\weights2-27.hdf5\n",
      "Val_F1score =  0.6316666666666667\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.7455 - accuracy: 0.6936 - val_loss: 0.8729 - val_accuracy: 0.6317\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7036\n",
      "Epoch 28: saving model to model_save\\weights2-28.hdf5\n",
      "Val_F1score =  0.685\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 0.7238 - accuracy: 0.7036 - val_loss: 0.7976 - val_accuracy: 0.6850\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.7021\n",
      "Epoch 29: saving model to model_save\\weights2-29.hdf5\n",
      "Val_F1score =  0.685\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.7246 - accuracy: 0.7021 - val_loss: 0.7901 - val_accuracy: 0.6850\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.7014\n",
      "Epoch 30: saving model to model_save\\weights2-30.hdf5\n",
      "Val_F1score =  0.68\n",
      "117/117 [==============================] - 14s 118ms/step - loss: 0.7315 - accuracy: 0.7014 - val_loss: 0.7766 - val_accuracy: 0.6800\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.7350\n",
      "Epoch 31: saving model to model_save\\weights2-31.hdf5\n",
      "Val_F1score =  0.6666666666666666\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6976 - accuracy: 0.7350 - val_loss: 0.8601 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.7336\n",
      "Epoch 32: saving model to model_save\\weights2-32.hdf5\n",
      "Val_F1score =  0.7116666666666667\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6818 - accuracy: 0.7336 - val_loss: 0.7626 - val_accuracy: 0.7117\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.7307\n",
      "Epoch 33: saving model to model_save\\weights2-33.hdf5\n",
      "Val_F1score =  0.7066666666666667\n",
      "117/117 [==============================] - 14s 119ms/step - loss: 0.6659 - accuracy: 0.7307 - val_loss: 0.7685 - val_accuracy: 0.7067\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7300\n",
      "Epoch 34: saving model to model_save\\weights2-34.hdf5\n",
      "Val_F1score =  0.7166666666666667\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6580 - accuracy: 0.7300 - val_loss: 0.8955 - val_accuracy: 0.7167\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.7364\n",
      "Epoch 35: saving model to model_save\\weights2-35.hdf5\n",
      "Val_F1score =  0.6616666666666666\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6490 - accuracy: 0.7364 - val_loss: 0.8979 - val_accuracy: 0.6617\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7400\n",
      "Epoch 36: saving model to model_save\\weights2-36.hdf5\n",
      "Val_F1score =  0.7250000000000001\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6522 - accuracy: 0.7400 - val_loss: 1.0058 - val_accuracy: 0.7250\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.7393\n",
      "Epoch 37: saving model to model_save\\weights2-37.hdf5\n",
      "Val_F1score =  0.7116666666666667\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6356 - accuracy: 0.7393 - val_loss: 1.1113 - val_accuracy: 0.7117\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.7500\n",
      "Epoch 38: saving model to model_save\\weights2-38.hdf5\n",
      "Val_F1score =  0.6983333333333334\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6341 - accuracy: 0.7500 - val_loss: 0.7945 - val_accuracy: 0.6983\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.6993\n",
      "Epoch 39: saving model to model_save\\weights2-39.hdf5\n",
      "Val_F1score =  0.6166666666666667\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.7577 - accuracy: 0.6993 - val_loss: 1.0327 - val_accuracy: 0.6167\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.7143\n",
      "Epoch 40: saving model to model_save\\weights2-40.hdf5\n",
      "Val_F1score =  0.6766666666666666\n",
      "117/117 [==============================] - 14s 121ms/step - loss: 0.7295 - accuracy: 0.7143 - val_loss: 0.8264 - val_accuracy: 0.6767\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7155 - accuracy: 0.7271\n",
      "Epoch 41: saving model to model_save\\weights2-41.hdf5\n",
      "Val_F1score =  0.6783333333333333\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.7155 - accuracy: 0.7271 - val_loss: 0.8394 - val_accuracy: 0.6783\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.7200\n",
      "Epoch 42: saving model to model_save\\weights2-42.hdf5\n",
      "Val_F1score =  0.6783333333333333\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6904 - accuracy: 0.7200 - val_loss: 0.8080 - val_accuracy: 0.6783\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.7379\n",
      "Epoch 43: saving model to model_save\\weights2-43.hdf5\n",
      "Val_F1score =  0.685\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6915 - accuracy: 0.7379 - val_loss: 0.8142 - val_accuracy: 0.6850\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7343\n",
      "Epoch 44: saving model to model_save\\weights2-44.hdf5\n",
      "Val_F1score =  0.635\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6676 - accuracy: 0.7343 - val_loss: 0.9934 - val_accuracy: 0.6350\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7030 - accuracy: 0.7236\n",
      "Epoch 45: saving model to model_save\\weights2-45.hdf5\n",
      "Val_F1score =  0.7016666666666667\n",
      "117/117 [==============================] - 14s 118ms/step - loss: 0.7030 - accuracy: 0.7236 - val_loss: 0.7993 - val_accuracy: 0.7017\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7400\n",
      "Epoch 46: saving model to model_save\\weights2-46.hdf5\n",
      "Val_F1score =  0.6716666666666666\n",
      "117/117 [==============================] - 14s 119ms/step - loss: 0.6594 - accuracy: 0.7400 - val_loss: 0.8553 - val_accuracy: 0.6717\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.7321\n",
      "Epoch 47: saving model to model_save\\weights2-47.hdf5\n",
      "Val_F1score =  0.7116666666666667\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6590 - accuracy: 0.7321 - val_loss: 0.7882 - val_accuracy: 0.7117\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.7493\n",
      "Epoch 48: saving model to model_save\\weights2-48.hdf5\n",
      "Val_F1score =  0.7183333333333334\n",
      "117/117 [==============================] - 14s 118ms/step - loss: 0.6301 - accuracy: 0.7493 - val_loss: 0.7641 - val_accuracy: 0.7183\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.7414\n",
      "Epoch 49: saving model to model_save\\weights2-49.hdf5\n",
      "Val_F1score =  0.605\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6549 - accuracy: 0.7414 - val_loss: 1.0156 - val_accuracy: 0.6050\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.7536\n",
      "Epoch 50: saving model to model_save\\weights2-50.hdf5\n",
      "Val_F1score =  0.7116666666666667\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6554 - accuracy: 0.7536 - val_loss: 0.7404 - val_accuracy: 0.7117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27626dc8c70>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=50,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.7379\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.6866666666666666\n",
      "117/117 [==============================] - 13s 110ms/step - loss: 0.6230 - accuracy: 0.7379 - val_loss: 0.8500 - val_accuracy: 0.6867\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6366 - accuracy: 0.7557\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.6933333333333334\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6366 - accuracy: 0.7557 - val_loss: 0.8109 - val_accuracy: 0.6933\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7400\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 0.6413 - accuracy: 0.7400 - val_loss: 0.7425 - val_accuracy: 0.7233\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.7621\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.6883333333333334\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6148 - accuracy: 0.7621 - val_loss: 0.8257 - val_accuracy: 0.6883\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.7400\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.6966666666666667\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6295 - accuracy: 0.7400 - val_loss: 0.7999 - val_accuracy: 0.6967\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.7743\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.7066666666666667\n",
      "117/117 [==============================] - 14s 118ms/step - loss: 0.5890 - accuracy: 0.7743 - val_loss: 0.7715 - val_accuracy: 0.7067\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.7650\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.6683333333333333\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6073 - accuracy: 0.7650 - val_loss: 1.2529 - val_accuracy: 0.6683\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.7571\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.74\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6226 - accuracy: 0.7571 - val_loss: 0.7389 - val_accuracy: 0.7400\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.7507\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.7183333333333334\n",
      "117/117 [==============================] - 14s 115ms/step - loss: 0.5980 - accuracy: 0.7507 - val_loss: 0.8194 - val_accuracy: 0.7183\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5737 - accuracy: 0.7729\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.7266666666666666\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.5737 - accuracy: 0.7729 - val_loss: 0.7342 - val_accuracy: 0.7267\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.7279\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.6883333333333334\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.8611 - accuracy: 0.7279 - val_loss: 0.8116 - val_accuracy: 0.6883\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7436\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.6916666666666667\n",
      "117/117 [==============================] - 14s 118ms/step - loss: 0.6781 - accuracy: 0.7436 - val_loss: 0.7784 - val_accuracy: 0.6917\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.7400\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.72\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6682 - accuracy: 0.7400 - val_loss: 0.7623 - val_accuracy: 0.7200\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.7500\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.6933333333333334\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6583 - accuracy: 0.7500 - val_loss: 0.8154 - val_accuracy: 0.6933\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7486\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.6733333333333333\n",
      "117/117 [==============================] - 14s 117ms/step - loss: 0.6569 - accuracy: 0.7486 - val_loss: 0.8519 - val_accuracy: 0.6733\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7550\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.6966666666666667\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6485 - accuracy: 0.7550 - val_loss: 0.7970 - val_accuracy: 0.6967\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.7543\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.6733333333333333\n",
      "117/117 [==============================] - 14s 116ms/step - loss: 0.6514 - accuracy: 0.7543 - val_loss: 0.8241 - val_accuracy: 0.6733\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.7443\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.7066666666666667\n",
      "117/117 [==============================] - 13s 115ms/step - loss: 0.6606 - accuracy: 0.7443 - val_loss: 0.7641 - val_accuracy: 0.7067\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.7464\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.6916666666666667\n",
      "117/117 [==============================] - 13s 114ms/step - loss: 0.6580 - accuracy: 0.7464 - val_loss: 0.7792 - val_accuracy: 0.6917\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.7600\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.7083333333333334\n",
      "117/117 [==============================] - 13s 113ms/step - loss: 0.6345 - accuracy: 0.7600 - val_loss: 0.7749 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276266c5ed0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=20,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7429\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.7283333333333334\n",
      "117/117 [==============================] - 17s 145ms/step - loss: 0.6307 - accuracy: 0.7429 - val_loss: 0.7679 - val_accuracy: 0.7283\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7614\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.7183333333333334\n",
      "117/117 [==============================] - 17s 146ms/step - loss: 0.6241 - accuracy: 0.7614 - val_loss: 0.7247 - val_accuracy: 0.7183\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.7529\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.7266666666666666\n",
      "117/117 [==============================] - 17s 147ms/step - loss: 0.6210 - accuracy: 0.7529 - val_loss: 0.7301 - val_accuracy: 0.7267\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.7586\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.695\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.6258 - accuracy: 0.7586 - val_loss: 0.7963 - val_accuracy: 0.6950\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.7700\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 0.6147 - accuracy: 0.7700 - val_loss: 0.7272 - val_accuracy: 0.7233\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7557\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.6127 - accuracy: 0.7557 - val_loss: 0.7250 - val_accuracy: 0.7233\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.7543\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.7116666666666667\n",
      "117/117 [==============================] - 14s 124ms/step - loss: 0.6312 - accuracy: 0.7543 - val_loss: 0.7171 - val_accuracy: 0.7117\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.7629\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.72\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.6094 - accuracy: 0.7629 - val_loss: 0.7318 - val_accuracy: 0.7200\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.7679\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.745\n",
      "117/117 [==============================] - 14s 122ms/step - loss: 0.5903 - accuracy: 0.7679 - val_loss: 0.7096 - val_accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.7586\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.6143 - accuracy: 0.7586 - val_loss: 0.7127 - val_accuracy: 0.7233\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.7629\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.755\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 0.6097 - accuracy: 0.7629 - val_loss: 0.7049 - val_accuracy: 0.7550\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7593\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.7166666666666667\n",
      "117/117 [==============================] - 14s 123ms/step - loss: 0.5986 - accuracy: 0.7593 - val_loss: 0.7383 - val_accuracy: 0.7167\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.7629\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 14s 124ms/step - loss: 0.6060 - accuracy: 0.7629 - val_loss: 0.7260 - val_accuracy: 0.7233\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7714\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.715\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.5732 - accuracy: 0.7714 - val_loss: 0.7327 - val_accuracy: 0.7150\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7636\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.7233333333333334\n",
      "117/117 [==============================] - 14s 124ms/step - loss: 0.6028 - accuracy: 0.7636 - val_loss: 0.7169 - val_accuracy: 0.7233\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.7636\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.715\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 0.5948 - accuracy: 0.7636 - val_loss: 0.7245 - val_accuracy: 0.7150\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.7693\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.7183333333333334\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.5978 - accuracy: 0.7693 - val_loss: 0.7330 - val_accuracy: 0.7183\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.7657\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.7216666666666668\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5851 - accuracy: 0.7657 - val_loss: 0.7188 - val_accuracy: 0.7217\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7579\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.7483333333333333\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 0.5990 - accuracy: 0.7579 - val_loss: 0.7002 - val_accuracy: 0.7483\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.7614\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.7100000000000001\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.5980 - accuracy: 0.7614 - val_loss: 0.7399 - val_accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27626dec1c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=20,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.7750\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.7316666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5753 - accuracy: 0.7750 - val_loss: 0.7146 - val_accuracy: 0.7317\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7714\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.6933333333333334\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5740 - accuracy: 0.7714 - val_loss: 0.8082 - val_accuracy: 0.6933\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7671\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.7333333333333333\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.6071 - accuracy: 0.7671 - val_loss: 0.7077 - val_accuracy: 0.7333\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.7743\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.75\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.5752 - accuracy: 0.7743 - val_loss: 0.7149 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7857\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.7483333333333333\n",
      "117/117 [==============================] - 15s 124ms/step - loss: 0.5470 - accuracy: 0.7857 - val_loss: 0.6608 - val_accuracy: 0.7483\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7764\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.715\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5708 - accuracy: 0.7764 - val_loss: 0.7534 - val_accuracy: 0.7150\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7679\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.745\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5652 - accuracy: 0.7679 - val_loss: 0.6819 - val_accuracy: 0.7450\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7864\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.7333333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.5473 - accuracy: 0.7864 - val_loss: 0.6758 - val_accuracy: 0.7333\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.7836\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.7566666666666667\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5537 - accuracy: 0.7836 - val_loss: 0.6668 - val_accuracy: 0.7567\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.7850\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.7566666666666667\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 0.5524 - accuracy: 0.7850 - val_loss: 0.6558 - val_accuracy: 0.7567\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.7993\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.7383333333333333\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5505 - accuracy: 0.7993 - val_loss: 0.6792 - val_accuracy: 0.7383\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.7843\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.7483333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5442 - accuracy: 0.7843 - val_loss: 0.6576 - val_accuracy: 0.7483\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7800\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.7416666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5470 - accuracy: 0.7800 - val_loss: 0.6955 - val_accuracy: 0.7417\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7943\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.76\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.5488 - accuracy: 0.7943 - val_loss: 0.6993 - val_accuracy: 0.7600\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7864\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.735\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.5379 - accuracy: 0.7864 - val_loss: 0.6650 - val_accuracy: 0.7350\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.7700\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.76\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5663 - accuracy: 0.7700 - val_loss: 0.6511 - val_accuracy: 0.7600\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.8029\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.6883333333333334\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5390 - accuracy: 0.8029 - val_loss: 0.8522 - val_accuracy: 0.6883\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7843\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.7666666666666667\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.5453 - accuracy: 0.7843 - val_loss: 0.6280 - val_accuracy: 0.7667\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.7850\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.7633333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.5277 - accuracy: 0.7850 - val_loss: 0.6789 - val_accuracy: 0.7633\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.7929\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.7733333333333333\n",
      "117/117 [==============================] - 16s 133ms/step - loss: 0.5251 - accuracy: 0.7929 - val_loss: 0.6367 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2762e431c30>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=20,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.7886\n",
      "Epoch 1: saving model to model_save\\weights2-01.hdf5\n",
      "Val_F1score =  0.75\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5319 - accuracy: 0.7886 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7993\n",
      "Epoch 2: saving model to model_save\\weights2-02.hdf5\n",
      "Val_F1score =  0.7566666666666667\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.5262 - accuracy: 0.7993 - val_loss: 0.6591 - val_accuracy: 0.7567\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.7936\n",
      "Epoch 3: saving model to model_save\\weights2-03.hdf5\n",
      "Val_F1score =  0.7299999999999999\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5160 - accuracy: 0.7936 - val_loss: 0.7539 - val_accuracy: 0.7300\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.7921\n",
      "Epoch 4: saving model to model_save\\weights2-04.hdf5\n",
      "Val_F1score =  0.7133333333333335\n",
      "117/117 [==============================] - 15s 131ms/step - loss: 0.5243 - accuracy: 0.7921 - val_loss: 0.7936 - val_accuracy: 0.7133\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.7964\n",
      "Epoch 5: saving model to model_save\\weights2-05.hdf5\n",
      "Val_F1score =  0.7816666666666666\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.5182 - accuracy: 0.7964 - val_loss: 0.6449 - val_accuracy: 0.7817\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7943\n",
      "Epoch 6: saving model to model_save\\weights2-06.hdf5\n",
      "Val_F1score =  0.7566666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.5080 - accuracy: 0.7943 - val_loss: 0.6423 - val_accuracy: 0.7567\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8107\n",
      "Epoch 7: saving model to model_save\\weights2-07.hdf5\n",
      "Val_F1score =  0.7666666666666667\n",
      "117/117 [==============================] - 15s 130ms/step - loss: 0.5061 - accuracy: 0.8107 - val_loss: 0.6415 - val_accuracy: 0.7667\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.8043\n",
      "Epoch 8: saving model to model_save\\weights2-08.hdf5\n",
      "Val_F1score =  0.7883333333333333\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.4971 - accuracy: 0.8043 - val_loss: 0.6057 - val_accuracy: 0.7883\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.8086\n",
      "Epoch 9: saving model to model_save\\weights2-09.hdf5\n",
      "Val_F1score =  0.7683333333333333\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.4854 - accuracy: 0.8086 - val_loss: 0.6248 - val_accuracy: 0.7683\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.8050\n",
      "Epoch 10: saving model to model_save\\weights2-10.hdf5\n",
      "Val_F1score =  0.78\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.4993 - accuracy: 0.8050 - val_loss: 0.6873 - val_accuracy: 0.7800\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8121\n",
      "Epoch 11: saving model to model_save\\weights2-11.hdf5\n",
      "Val_F1score =  0.79\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.4743 - accuracy: 0.8121 - val_loss: 0.5993 - val_accuracy: 0.7900\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8057\n",
      "Epoch 12: saving model to model_save\\weights2-12.hdf5\n",
      "Val_F1score =  0.7566666666666667\n",
      "117/117 [==============================] - 15s 128ms/step - loss: 0.4753 - accuracy: 0.8057 - val_loss: 0.6291 - val_accuracy: 0.7567\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8200\n",
      "Epoch 13: saving model to model_save\\weights2-13.hdf5\n",
      "Val_F1score =  0.8033333333333333\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.4634 - accuracy: 0.8200 - val_loss: 0.5771 - val_accuracy: 0.8033\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.8193\n",
      "Epoch 14: saving model to model_save\\weights2-14.hdf5\n",
      "Val_F1score =  0.79\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.4668 - accuracy: 0.8193 - val_loss: 0.5778 - val_accuracy: 0.7900\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8314\n",
      "Epoch 15: saving model to model_save\\weights2-15.hdf5\n",
      "Val_F1score =  0.7683333333333333\n",
      "117/117 [==============================] - 15s 124ms/step - loss: 0.4557 - accuracy: 0.8314 - val_loss: 0.6153 - val_accuracy: 0.7683\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.8093\n",
      "Epoch 16: saving model to model_save\\weights2-16.hdf5\n",
      "Val_F1score =  0.8066666666666665\n",
      "117/117 [==============================] - 15s 127ms/step - loss: 0.4695 - accuracy: 0.8093 - val_loss: 0.5739 - val_accuracy: 0.8067\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8250\n",
      "Epoch 17: saving model to model_save\\weights2-17.hdf5\n",
      "Val_F1score =  0.7583333333333333\n",
      "117/117 [==============================] - 15s 125ms/step - loss: 0.4394 - accuracy: 0.8250 - val_loss: 0.6216 - val_accuracy: 0.7583\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8264\n",
      "Epoch 18: saving model to model_save\\weights2-18.hdf5\n",
      "Val_F1score =  0.7466666666666667\n",
      "117/117 [==============================] - 15s 126ms/step - loss: 0.4513 - accuracy: 0.8264 - val_loss: 0.6632 - val_accuracy: 0.7467\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.8186\n",
      "Epoch 19: saving model to model_save\\weights2-19.hdf5\n",
      "Val_F1score =  0.8016666666666666\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.4571 - accuracy: 0.8186 - val_loss: 0.5568 - val_accuracy: 0.8017\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8179\n",
      "Epoch 20: saving model to model_save\\weights2-20.hdf5\n",
      "Val_F1score =  0.795\n",
      "117/117 [==============================] - 15s 129ms/step - loss: 0.4641 - accuracy: 0.8179 - val_loss: 0.5949 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27626d38af0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_int, epochs=20,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_F1score =  0.8016666666666666\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights('model_save/weights2-19.hdf5')\n",
    "val_predict = (np.asarray(model1.predict(X_test_spectrogram)))\n",
    "val_label=np.argmax(val_predict,axis=1)\n",
    "val_targ = y_test_int\n",
    "val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8410717687a28d03\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8410717687a28d03\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs1/fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='model2.png'\n",
    "tf.keras.utils.plot_model(model1,to_file=filepath,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "862fP2e-aNp3"
   },
   "outputs": [],
   "source": [
    "#compile and fit your model.\n",
    "#model2.fit([X_train_spectrogram],y_train_int,......)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSl8ZOXjaNqJ"
   },
   "source": [
    "### 3. Data augmentation with raw features \n",
    "\n",
    "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
    "\n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jR4JSEDgaNqK"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path,get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "QRdefb-SaNqS"
   },
   "outputs": [],
   "source": [
    "temp_path = df_audio.iloc[0].path\n",
    "aug_temp = generate_augmented_data(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "kzdG3iS-aNqc",
    "outputId": "0f17e45e-63a0-4986-8f69-05e2dbd71bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckytZsraNqk"
   },
   "source": [
    "## Follow the steps \n",
    "\n",
    "1. Split data 'df_audio' into train and test (80-20 split)\n",
    "\n",
    "2. We have 2000 data points(1600 train points, 400 test points) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LFo5SnTLO_sD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(df_audio['path'],df_audio['label'],random_state=45,test_size=0.2,stratify=df_audio['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdKXVRlpaNql"
   },
   "source": [
    "3. Do augmentation only on X_train,pass each point of X_train to generate_augmented_data function.After augmentation we will get 14400 train points. Make sure that you are augmenting the corresponding class labels (y_train) also.\n",
    "4. Preprocess your X_test using load_wav function.\n",
    "5. Convert the augmented_train_data and test_data to numpy arrays.\n",
    "6. Perform padding and masking on augmented_train_data and test_data.\n",
    "7. After padding define the model similar to model 1 and fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented=[]\n",
    "y_train_aug=[]\n",
    "for x,y in zip(X_train,y_train):\n",
    "    temp_aug= generate_augmented_data(x)\n",
    "    X_train_augmented.extend(temp_aug)\n",
    "    y_train_aug.extend([y]*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25880\\1686762254.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_augmented= np.array(X_train_augmented)\n"
     ]
    }
   ],
   "source": [
    "X_train_augmented= np.array(X_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('train_augmented','wb') as f: \n",
    "#     pickle.dump(X_train_augmented, f)\n",
    "    \n",
    "# with open('y_train_augmented','wb') as f: \n",
    "#     pickle.dump(y_train_aug, f)\n",
    "\n",
    "with open('train_augmented','rb') as f: \n",
    "    X_train_augmented1 = pickle.load(f)\n",
    "    \n",
    "with open('y_train_augmented','rb') as f: \n",
    "    y_train_augmented1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_augmented1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_augmented1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2495104e-05, -6.2195526e-05, -1.0654096e-04, ...,\n",
       "       -1.5071427e-04, -3.4051077e-04,  0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_augmented1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_augmented1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7.5200514e-05, 0.00067946606, 0.0011661825, 0...</td>\n",
       "      <td>0.316281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00746698, -0.0061093145, -0.0028450494, 0....</td>\n",
       "      <td>0.374785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.010753613, -0.0025474587, 0.006818897, 0.0...</td>\n",
       "      <td>0.569751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.008190532, -0.005059408, 0.005092152, 0.01...</td>\n",
       "      <td>0.381270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.00034301207, 0.0002433633, 4.777004e-05, -0...</td>\n",
       "      <td>0.453878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [7.5200514e-05, 0.00067946606, 0.0011661825, 0...  0.316281\n",
       "1  [-0.00746698, -0.0061093145, -0.0028450494, 0....  0.374785\n",
       "2  [-0.010753613, -0.0025474587, 0.006818897, 0.0...  0.569751\n",
       "3  [-0.008190532, -0.005059408, 0.005092152, 0.01...  0.381270\n",
       "4  [0.00034301207, 0.0002433633, 4.777004e-05, -0...  0.453878"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed = []\n",
    "for x in X_test:\n",
    "    X_test_processed.append(load_wav(x, get_duration=True))\n",
    "X_test_processed=pd.DataFrame(X_test_processed,columns=['raw_data','duration'])\n",
    "X_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad_seq=[]\n",
    "X_train_mask=[]\n",
    "for x in X_train_augmented1:\n",
    "    if len(x)<17640:\n",
    "        x1=np.concatenate((x , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_train_pad_seq.append(x1)\n",
    "        mask=np.concatenate((np.ones(len(x), dtype=bool) , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_train_mask.append(mask)\n",
    "        \n",
    "    else:\n",
    "        X_train_pad_seq.append(x[:17640])\n",
    "        X_train_mask.append(np.ones(17640, dtype=bool))\n",
    "        \n",
    "X_train_pad_seq= np.array(X_train_pad_seq)\n",
    "X_train_mask = np.array(X_train_mask)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad_seq=[]\n",
    "X_test_mask=[]\n",
    "for x in X_test_processed['raw_data']:\n",
    "    if len(x)<17640:\n",
    "        x1=np.concatenate((x , np.zeros(17640-len(x),dtype=bool)))\n",
    "        X_test_pad_seq.append(x1)\n",
    "        mask=np.concatenate((np.ones(len(x),dtype=bool) , np.zeros(17640-len(x), dtype=bool)))\n",
    "        X_test_mask.append(mask)\n",
    "        \n",
    "    else:\n",
    "        X_test_pad_seq.append(x[:17640])\n",
    "        X_test_mask.append(np.ones(17640,dtype=bool))\n",
    "        \n",
    "X_test_pad_seq= np.array(X_test_pad_seq)\n",
    "X_test_mask = np.array(X_test_mask)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "class Metrics(tf.keras.callbacks.Callback ):\n",
    "    def __init__(self,validation_data):\n",
    "\n",
    "        super().__init__()\n",
    "        self.x_test=validation_data[0]\n",
    "        self.y_test=validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        val_predict = (np.asarray(self.model.predict([self.x_test[0],self.x_test[1]])))\n",
    "        val_label=np.argmax(val_predict,axis=1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "        print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 17640)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           4352        ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           2112        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           650         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,114\n",
      "Trainable params: 7,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer= Input(shape=(17640,1))\n",
    "input_layer2 = Input( shape=(17640,))\n",
    "lstm = LSTM(32, activation='relu')(inputs=input_layer, mask=input_layer2)\n",
    "dense= Dense(64, activation='relu')(lstm)\n",
    "output= Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model= Model([input_layer,input_layer2],output)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "log_dir = os.path.join(\"logs1\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "\n",
    "filepath=\"model_save/weights3-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_f1', verbose=1, mode='auto')  \n",
    "metric = Metrics(validation_data=[[X_test_pad_seq,X_test_mask],y_test_int])\n",
    "\n",
    "callbacks= [tensorboard_callback,checkpoint, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_aug=np.array(y_train_augmented1,dtype=int)\n",
    "y_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_int = y_test.apply(lambda x: int(x))\n",
    "y_test_int=y_test_int.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17640"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_pad_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - ETA: 0s - loss: 2.3030 \n",
      "Epoch 1: saving model to model_save\\weights3-01.hdf5\n",
      "Val_F1score =  0.10000000000000002\n",
      "1200/1200 [==============================] - 23553s 20s/step - loss: 2.3030 - val_loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2698a20cb20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_pad_seq,X_train_mask], y_train_aug, epochs=1,verbose=1,batch_size=12, callbacks =callbacks, validation_data=([X_test_pad_seq,X_test_mask],y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_F1score =  0.10000000000000002\n"
     ]
    }
   ],
   "source": [
    "val_predict = (np.asarray(model.predict([X_test_pad_seq,X_test_mask])))\n",
    "val_label=np.argmax(val_predict,axis=1)\n",
    "val_targ = y_test_int\n",
    "val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-551563f7b50715ad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-551563f7b50715ad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs1/fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8Yh72uYO_sD"
   },
   "source": [
    "<font color='red'> Note </font> - While fitting your model on the augmented data for model 3 you might face Resource exhaust error. One simple hack to avoid that is save the augmented_train_data,augment_y_train,test_data and y_test to Drive or into your local system. Then restart the runtime so that now you can train your model with full RAM capacity. Upload these files again in the new runtime session perform padding and masking and then fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wBwzbjOzO_sD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='model3.png'\n",
    "tf.keras.utils.plot_model(model,to_file=filepath,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41vU8M1gO_sD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXY9uP7cO_sE"
   },
   "source": [
    "### 4. Data augmentation with spectogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EShBfiERO_sE"
   },
   "source": [
    "1. use convert_to_spectrogram and convert the padded data from train and test data to spectogram data.\n",
    "2. The shape of train data will be 14400 x 64 x 35 and shape of test_data will be 400 x 64 x35\n",
    "3. Define the model similar to model 2 and fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QpVMCEW3O_sE"
   },
   "outputs": [],
   "source": [
    "X_train_spectrogram = convert_to_spectrogram(X_train_pad_seq)\n",
    "X_test_spectrogram = convert_to_spectrogram(X_test_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 64, 35)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "40RMwgJ6O_sE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 35)]          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64, 32)            8704      \n",
      "                                                                 \n",
      " tf.math.reduce_mean_2 (TFOp  (None, 64)               0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,114\n",
      "Trainable params: 11,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.python.keras.layers.core import TFOpLambda\n",
    "\n",
    "def mean_layer(x):\n",
    "    return tf.math.reduce_mean(x,axis=2)\n",
    "\n",
    "input_layer= Input(shape=(64,35))\n",
    "lstm = LSTM(32, activation='relu', return_sequences=True)(input_layer)\n",
    "mean= TFOpLambda(mean_layer)(lstm)\n",
    "#AvgPool = GlobalAveragePooling1D()(mean)\n",
    "dense= Dense(32, activation='relu')(mean)\n",
    "output= Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model1= Model(input_layer,output)\n",
    "model1.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics='accuracy')\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "class Metrics(tf.keras.callbacks.Callback ):\n",
    "    def __init__(self,validation_data):\n",
    "\n",
    "        super().__init__()\n",
    "        self.x_test=validation_data[0]\n",
    "        self.y_test=validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "        val_label=np.argmax(val_predict,axis=1)\n",
    "        val_targ = self.y_test\n",
    "        val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "        print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "log_dir = os.path.join(\"logs1\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "\n",
    "filepath=\"model_save4/weights4-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_f1',  verbose=1, mode='auto')  \n",
    "metric = Metrics(validation_data=[X_test_spectrogram,y_test_int])\n",
    "\n",
    "callbacks= [tensorboard_callback,checkpoint, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.3413 - accuracy: 0.1475\n",
      "Epoch 1: saving model to model_save4\\weights4-01.hdf5\n",
      "Val_F1score =  0.22\n",
      "1200/1200 [==============================] - 81s 67ms/step - loss: 2.3413 - accuracy: 0.1475 - val_loss: 2.1427 - val_accuracy: 0.2200\n",
      "Epoch 2/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.9153 - accuracy: 0.2999\n",
      "Epoch 2: saving model to model_save4\\weights4-02.hdf5\n",
      "Val_F1score =  0.37333333333333335\n",
      "1200/1200 [==============================] - 80s 67ms/step - loss: 1.9153 - accuracy: 0.2999 - val_loss: 1.7522 - val_accuracy: 0.3733\n",
      "Epoch 3/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.5387 - accuracy: 0.4473\n",
      "Epoch 3: saving model to model_save4\\weights4-03.hdf5\n",
      "Val_F1score =  0.51\n",
      "1200/1200 [==============================] - 84s 70ms/step - loss: 1.5387 - accuracy: 0.4473 - val_loss: 1.3634 - val_accuracy: 0.5100\n",
      "Epoch 4/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.2081 - accuracy: 0.5649\n",
      "Epoch 4: saving model to model_save4\\weights4-04.hdf5\n",
      "Val_F1score =  0.6316666666666667\n",
      "1200/1200 [==============================] - 85s 70ms/step - loss: 1.2081 - accuracy: 0.5649 - val_loss: 1.0626 - val_accuracy: 0.6317\n",
      "Epoch 5/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.9683 - accuracy: 0.6431\n",
      "Epoch 5: saving model to model_save4\\weights4-05.hdf5\n",
      "Val_F1score =  0.67\n",
      "1200/1200 [==============================] - 84s 70ms/step - loss: 0.9683 - accuracy: 0.6431 - val_loss: 0.8786 - val_accuracy: 0.6700\n",
      "Epoch 6/100\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.8010 - accuracy: 0.7052\n",
      "Epoch 6: saving model to model_save4\\weights4-06.hdf5\n",
      "Val_F1score =  0.7466666666666667\n",
      "1200/1200 [==============================] - 81s 67ms/step - loss: 0.8010 - accuracy: 0.7052 - val_loss: 0.7281 - val_accuracy: 0.7467\n",
      "Epoch 7/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.7385\n",
      "Epoch 7: saving model to model_save4\\weights4-07.hdf5\n",
      "Val_F1score =  0.7699999999999999\n",
      "1200/1200 [==============================] - 83s 69ms/step - loss: 0.6934 - accuracy: 0.7385 - val_loss: 0.6080 - val_accuracy: 0.7700\n",
      "Epoch 8/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7700\n",
      "Epoch 8: saving model to model_save4\\weights4-08.hdf5\n",
      "Val_F1score =  0.8016666666666666\n",
      "1200/1200 [==============================] - 77s 64ms/step - loss: 0.6175 - accuracy: 0.7700 - val_loss: 0.5247 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.7933\n",
      "Epoch 9: saving model to model_save4\\weights4-09.hdf5\n",
      "Val_F1score =  0.8666666666666667\n",
      "1200/1200 [==============================] - 75s 63ms/step - loss: 0.5643 - accuracy: 0.7933 - val_loss: 0.4496 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.8109\n",
      "Epoch 10: saving model to model_save4\\weights4-10.hdf5\n",
      "Val_F1score =  0.8633333333333333\n",
      "1200/1200 [==============================] - 78s 65ms/step - loss: 0.5176 - accuracy: 0.8109 - val_loss: 0.4293 - val_accuracy: 0.8633\n",
      "Epoch 11/100\n",
      " 920/1200 [======================>.......] - ETA: 17s - loss: 0.4910 - accuracy: 0.8185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_spectrogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_spectrogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test_int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.fit(X_train_spectrogram, y_train_aug, epochs=100,verbose=1,batch_size=12, callbacks =callbacks, validation_data=(X_test_spectrogram,y_test_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights('weights4-10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_F1score =  0.8633333333333333\n"
     ]
    }
   ],
   "source": [
    "val_predict = (np.asarray(model1.predict(X_test_spectrogram)))\n",
    "val_label=np.argmax(val_predict,axis=1)\n",
    "val_targ = y_test_int\n",
    "val_f1 = f1_score(val_targ, val_label,average='micro')\n",
    "print (\"Val_F1score = \",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19088), started 10:20:12 ago. (Use '!kill 19088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-73ffb039baeb2b34\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-73ffb039baeb2b34\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs1/fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath='model4.png'\n",
    "tf.keras.utils.plot_model(model1,to_file=filepath,show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
